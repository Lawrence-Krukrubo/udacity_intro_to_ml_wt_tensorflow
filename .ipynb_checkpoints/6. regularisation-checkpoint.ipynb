{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularisation:\n",
    "Is a very useful technique to improve our models and ensure they dont overfit. Regularisation basically takes the complexity of a model into cnsideration when calculating the error. And by so doing simpler models would normally score less error levels than complex models. This final score is weighted by a factor called **lambda** ($\\lambda$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the compleity of a model as part of the error:\n",
    "#### L1 regularisation:\n",
    "* We add the absolute values of the model coefficients to the error\n",
    "\n",
    "#### L2 regularisation:\n",
    "* We add the squared values of the model coefficients to the error\n",
    "\n",
    "By default, both L1 and L2 regularisations tend to punish complex models more. But the question is what need do we need?\n",
    "If the problem requires a higher accuracy and precision, with little chance for error, like a model to predict the onset of a heart attack or flight to the moon, then we can penalize the complex model less, while penalizing more to a less strategic model that requires lower accuracy, such as a model to recommend friends to a new user.\n",
    "\n",
    "Thus in every case, we want to tune howmuch we punish complexity in each model. Therefore we use a parameter called **Lambda** ($\\lambda$) to regularize how much we tune these models based on either L1 or L2 regularisation methods.\n",
    "\n",
    "In summary, if we have a large lambda, then we're multiplying the complexity part (The coefficients) of the model with a lot, which punishes the more complex model more and favors a simpler model. While a small lambda multiplies a little to the complexity part of the model, which punishes a simpler model more and favors more complex, more precise models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.25664,2.04978,-6.23640,4.71926,-4.26931,0.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.89012,-0.37511,6.14979,4.94585,-3.57844,0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.09784,0.98120,-0.29939,5.85805,0.28297,-0.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.39034,-3.06861,-5.63488,6.43941,0.39256,-0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.84727,-0.15922,11.41246,7.52165,1.69886,0.29...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  1.25664,2.04978,-6.23640,4.71926,-4.26931,0.20...\n",
       "1  -3.89012,-0.37511,6.14979,4.94585,-3.57844,0.0...\n",
       "2  5.09784,0.98120,-0.29939,5.85805,0.28297,-0.20...\n",
       "3  0.39034,-3.06861,-5.63488,6.43941,0.39256,-0.0...\n",
       "4  5.84727,-0.15922,11.41246,7.52165,1.69886,0.29..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/regularisation_dataset.csv', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.25664</td>\n",
       "      <td>2.04978</td>\n",
       "      <td>-6.23640</td>\n",
       "      <td>4.71926</td>\n",
       "      <td>-4.26931</td>\n",
       "      <td>0.20590</td>\n",
       "      <td>12.31798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.89012</td>\n",
       "      <td>-0.37511</td>\n",
       "      <td>6.14979</td>\n",
       "      <td>4.94585</td>\n",
       "      <td>-3.57844</td>\n",
       "      <td>0.00640</td>\n",
       "      <td>23.67628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.09784</td>\n",
       "      <td>0.98120</td>\n",
       "      <td>-0.29939</td>\n",
       "      <td>5.85805</td>\n",
       "      <td>0.28297</td>\n",
       "      <td>-0.20626</td>\n",
       "      <td>-1.53459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.39034</td>\n",
       "      <td>-3.06861</td>\n",
       "      <td>-5.63488</td>\n",
       "      <td>6.43941</td>\n",
       "      <td>0.39256</td>\n",
       "      <td>-0.07084</td>\n",
       "      <td>-24.68670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.84727</td>\n",
       "      <td>-0.15922</td>\n",
       "      <td>11.41246</td>\n",
       "      <td>7.52165</td>\n",
       "      <td>1.69886</td>\n",
       "      <td>0.29022</td>\n",
       "      <td>17.54122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2        3         4         5          6\n",
       "0   1.25664   2.04978  -6.23640  4.71926  -4.26931   0.20590   12.31798\n",
       "1  -3.89012  -0.37511   6.14979  4.94585  -3.57844   0.00640   23.67628\n",
       "2   5.09784   0.98120  -0.29939  5.85805   0.28297  -0.20626   -1.53459\n",
       "3   0.39034  -3.06861  -5.63488  6.43941   0.39256  -0.07084  -24.68670\n",
       "4   5.84727  -0.15922  11.41246  7.52165   1.69886   0.29022   17.54122"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's expand the single string column 0 into the required 7 different columns\n",
    "df = df[0].str.split(',', expand=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 7 columns):\n",
      "0    100 non-null object\n",
      "1    100 non-null object\n",
      "2    100 non-null object\n",
      "3    100 non-null object\n",
      "4    100 non-null object\n",
      "5    100 non-null object\n",
      "6    100 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 5.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 7 columns):\n",
      "0    100 non-null float64\n",
      "1    100 non-null float64\n",
      "2    100 non-null float64\n",
      "3    100 non-null float64\n",
      "4    100 non-null float64\n",
      "5    100 non-null float64\n",
      "6    100 non-null float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 5.6 KB\n"
     ]
    }
   ],
   "source": [
    "# finally, let's convert all columns from string to float\n",
    "df = df.apply(pd.to_numeric)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.25664</td>\n",
       "      <td>2.04978</td>\n",
       "      <td>-6.23640</td>\n",
       "      <td>4.71926</td>\n",
       "      <td>-4.26931</td>\n",
       "      <td>0.20590</td>\n",
       "      <td>12.31798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.89012</td>\n",
       "      <td>-0.37511</td>\n",
       "      <td>6.14979</td>\n",
       "      <td>4.94585</td>\n",
       "      <td>-3.57844</td>\n",
       "      <td>0.00640</td>\n",
       "      <td>23.67628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.09784</td>\n",
       "      <td>0.98120</td>\n",
       "      <td>-0.29939</td>\n",
       "      <td>5.85805</td>\n",
       "      <td>0.28297</td>\n",
       "      <td>-0.20626</td>\n",
       "      <td>-1.53459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2        3        4        5         6\n",
       "0  1.25664  2.04978 -6.23640  4.71926 -4.26931  0.20590  12.31798\n",
       "1 -3.89012 -0.37511  6.14979  4.94585 -3.57844  0.00640  23.67628\n",
       "2  5.09784  0.98120 -0.29939  5.85805  0.28297 -0.20626  -1.53459"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved!\n"
     ]
    }
   ],
   "source": [
    "# Let's save the updated dataframe\n",
    "df.to_csv('datasets/regularisation_dataset2.csv', index=False)\n",
    "print('saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's build a Linear Model and an L1 (lasso) model and see the coefficients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg = Lasso().fit(X, y)\n",
    "linear_reg = LinearRegression().fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Coefs: [ 0.          2.35793224  2.00441646 -0.05511954 -3.92808318  0.        ]\n",
      "\n",
      "Linear Coefs: [-6.19918532e-03  2.96325160e+00  1.98199191e+00 -7.86249920e-02\n",
      " -3.95818772e+00  9.30786141e+00]\n"
     ]
    }
   ],
   "source": [
    "print(f'Lasso Coefs: {lasso_reg.coef_}\\n\\nLinear Coefs: {linear_reg.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see how the **Lasso-Reg(L1 reg)** converts unimportant features coefficients to zero for features 1 and 6, while the regular **Linear-Reg** keeps these coefficients. L1 regularisation does this to irrelevant features whose penalty of removing them from the features is small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference Between L1 and L2 Reg:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. L1 is computationally inefficient, even though it seems simple, this is because those absolute values are hard to differentiate. Except, unless the data is sparse. While L2 is easier to compute as squares often have very nice derivatives.\n",
    "2. The only time L1 is better than L2 is if the data is sparse, such as having a 1000 features but only 10 are relevant and the rest are mostly zeroes. While L2 is better for non-sparse outputs.\n",
    "3. L1 has another benefit in that it gives us feature-selection. say for example we have 1000 features and most are irrelevant and noise, while only 10 are relevant, L1 will detect this and make the irrelevant columns into zeros as we saw in the Lasso/Linear reg exercises above. L2 on the other hand, won't do this, it will take all columns and treat them similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
